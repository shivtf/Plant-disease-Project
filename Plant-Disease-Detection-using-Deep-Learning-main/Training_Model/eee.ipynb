{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from itertools import accumulate\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "    'densenet121': 'https://download.pytorch.org/models/densenet121-241335ed.pth',\n",
    "    'inception_v3': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = model_urls.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sizes = {\n",
    "    'alexnet' : (224,224),\n",
    "    'densenet': (224,224),\n",
    "    'resnet' : (224,224),\n",
    "    'inception' : (299,299),\n",
    "    'squeezenet' : (224,224),#not 255,255 acc. to https://github.com/pytorch/pytorch/issues/1120\n",
    "    'vgg' : (224,224)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = ['alexnet','densenet121', 'inception_v3', 'resnet50', 'vgg16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = 'cuda' if use_gpu else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "def diff_states(state_dict1, state_dict2):\n",
    "    \"\"\"Helper function to compare model state dicts.\"\"\"\n",
    "    diff = []\n",
    "    for key in state_dict1:\n",
    "        if key in state_dict2 and not torch.equal(state_dict1[key], state_dict2[key]):\n",
    "            diff.append((key, state_dict2[key]))\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision import models\n",
    "\n",
    "# Define URLs for the pretrained models (example: ResNet, VGG, DenseNet, etc.)\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-f37072fd.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
    "    'inception_v3': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'\n",
    "}\n",
    "\n",
    "def load_defined_model(name, num_classes, device='cpu'):\n",
    "    model = models.__dict__[name](pretrained=False)  # Load the base model architecture\n",
    "\n",
    "    # Adjust the final classifier layer according to the architecture type\n",
    "    if name.startswith('resnet'):\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif name.startswith('vgg'):\n",
    "        model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    elif name.startswith('densenet'):\n",
    "        model.classifier = torch.nn.Linear(model.classifier.in_features, num_classes)\n",
    "    elif name == 'inception_v3':\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    # Move the model to the specified device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Load pretrained weights if the URL is available\n",
    "    if name in model_urls:\n",
    "        try:\n",
    "            pretrained_state = load_state_dict_from_url(model_urls[name], map_location=device)\n",
    "            print(f\"Pretrained weights loaded successfully for {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pretrained weights for {name}: {e}\")\n",
    "            pretrained_state = None\n",
    "    else:\n",
    "        print(f\"No pretrained model URL found for {name}\")\n",
    "        pretrained_state = None\n",
    "\n",
    "    # If pretrained weights are loaded, update the model's state dict with matching parameters\n",
    "    if pretrained_state:\n",
    "        model_state_dict = model.state_dict()\n",
    "        diff = []\n",
    "        for key in pretrained_state:\n",
    "            if key in model_state_dict and pretrained_state[key].shape == model_state_dict[key].shape:\n",
    "                model_state_dict[key] = pretrained_state[key]\n",
    "            else:\n",
    "                diff.append((key, pretrained_state[key]))\n",
    "\n",
    "        # Load the updated state dict into the model\n",
    "        model.load_state_dict(model_state_dict)\n",
    "    else:\n",
    "        diff = []  # No pretrained state, nothing to compare\n",
    "\n",
    "    return model, diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_params(net):\n",
    "    print(\"Model parameters:\")\n",
    "    for name, param in net.named_parameters():\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_params(net, param_list=None):\n",
    "    def in_param_list(s):\n",
    "        for p in param_list:\n",
    "            if s.endswith(p) or s.endswith(f\".module.{p}\"):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    params = net.named_parameters() if param_list is None \\\n",
    "        else (p for p in net.named_parameters() if in_param_list(p[0]))\n",
    "    \n",
    "    params = list(params)  # Convert generator to a list for debugging\n",
    "    \n",
    "    if len(params) == 0:\n",
    "        raise ValueError(\"No parameters matched the provided param_list.\")\n",
    "\n",
    "    filtered_params = [p for p in params if p[1].requires_grad]\n",
    "    \n",
    "    if len(filtered_params) == 0:\n",
    "        raise ValueError(\"No parameters with requires_grad=True were found to optimize.\")\n",
    "    \n",
    "    return filtered_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def load_data(resize, val_split=0.2):\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(max(resize)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    data_dir = '../plantvillage dataset/color'\n",
    "    full_dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    val_size = int(len(full_dataset) * val_split)\n",
    "    train_size = len(full_dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    valloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    return trainloader, valloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, param_list=None, epochs=2):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if use_gpu:\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    params = list(filtered_params(net, param_list))\n",
    "    print(\"Filtered parameters:\", params)\n",
    "\n",
    "    if len(params) == 0:\n",
    "        raise ValueError(\"No parameters to optimize were found.\")\n",
    "\n",
    "    if param_list:\n",
    "        for p_fixed in (p for p in net.named_parameters() if not any(p_name in p[0] for p_name in param_list)):\n",
    "            p_fixed[1].requires_grad = False            \n",
    "\n",
    "    optimizer = optim.SGD((p[1] for p in params), lr=0.001, momentum=0.9)\n",
    "    print(\"Optimizer parameters:\", list((p[1] for p in params)))\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = None\n",
    "            if isinstance(outputs, tuple):\n",
    "                loss = sum((criterion(o, labels) for o in outputs))\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data.item()\n",
    "            if i % 30 == 29:\n",
    "                avg_loss = running_loss / 30\n",
    "                losses.append(avg_loss)\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, avg_loss))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stats(m, trainloader, param_list=None):\n",
    "    stats = {}\n",
    "    params = filtered_params(m, param_list)\n",
    "    \n",
    "    counts = 0, 0\n",
    "    for counts in enumerate(accumulate((reduce(lambda d1, d2: d1 * d2, p[1].size()) for p in params))):\n",
    "        pass\n",
    "    stats['variables_optimized'] = counts[0] + 1\n",
    "    stats['params_optimized'] = counts[1]\n",
    "    \n",
    "    before = time.time()\n",
    "    losses = train(m, trainloader, param_list=param_list)\n",
    "    stats['training_time'] = time.time() - before\n",
    "\n",
    "    stats['training_loss'] = losses[-1] if len(losses) else float('nan')\n",
    "    stats['training_losses'] = losses\n",
    "    \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(network, test_loader):\n",
    "    evaluation_stats = {}\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for index, batch in enumerate(test_loader, 0):\n",
    "        images, labels = batch\n",
    "\n",
    "        if use_gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = network(Variable(images))\n",
    "        _, predicted_labels = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted_labels == labels).sum()\n",
    "    \n",
    "    accuracy = correct_predictions / total_samples\n",
    "    evaluation_stats['accuracy'] = accuracy\n",
    "    evaluation_stats['evaluation_time'] = time.time() - start_time\n",
    "    \n",
    "    print('Accuracy on test images: %f' % accuracy)\n",
    "    return evaluation_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETRAINING\n",
      "\n",
      "Targeting alexnet with 39 classes\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained model URL found for alexnet\n",
      "Resizing input images to max of (224, 224)\n",
      "Transferring models to GPU(s)\n",
      "Training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No parameters matched the provided param_list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransferring models to GPU(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m     model_pretrained \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(model_pretrained)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m---> 34\u001b[0m pretrained_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_pretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m pretrained_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m     36\u001b[0m pretrained_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrained\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[32], line 7\u001b[0m, in \u001b[0;36mtrain_eval\u001b[1;34m(network, training_loader, test_loader, param_list)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_eval\u001b[39m(network, training_loader, test_loader, param_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m param_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetraining...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     stats_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m     network \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m, in \u001b[0;36mtrain_stats\u001b[1;34m(m, trainloader, param_list)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_stats\u001b[39m(m, trainloader, param_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     stats \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m counts \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(accumulate((reduce(\u001b[38;5;28;01mlambda\u001b[39;00m d1, d2: d1 \u001b[38;5;241m*\u001b[39m d2, p[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params))):\n",
      "Cell \u001b[1;32mIn[27], line 14\u001b[0m, in \u001b[0;36mfiltered_params\u001b[1;34m(net, param_list)\u001b[0m\n\u001b[0;32m     11\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)  \u001b[38;5;66;03m# Convert generator to a list for debugging\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(params) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo parameters matched the provided param_list.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m filtered_params \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params \u001b[38;5;28;01mif\u001b[39;00m p[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrequires_grad]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(filtered_params) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: No parameters matched the provided param_list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import csv\n",
    "\n",
    "def train_eval(network, training_loader, test_loader, param_list=None):\n",
    "    print(\"Training...\" if not param_list else \"Retraining...\")\n",
    "    stats_train = train_stats(network, training_loader, param_list=param_list)\n",
    "    \n",
    "    print(\"Evaluating...\")\n",
    "    network = network.eval()\n",
    "    stats_eval = evaluate_model_performance(network, test_loader)\n",
    "    \n",
    "    return {**stats_train, **stats_eval}\n",
    "\n",
    "stats = []\n",
    "num_classes = 39\n",
    "print(\"RETRAINING\")\n",
    "\n",
    "for name in models_to_test:\n",
    "    print(\"\")\n",
    "    print(f\"Targeting {name} with {num_classes} classes\")\n",
    "    print(\"------------------------------------------\")\n",
    "    model_pretrained, diff = load_defined_model(name, num_classes, device='cuda' if use_gpu else 'cpu')\n",
    "    final_params = [p[0] for p in diff]\n",
    "    \n",
    "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
    "    print(f\"Resizing input images to max of {resize}\")\n",
    "    trainloader, testloader = load_data(resize)\n",
    "    \n",
    "    if use_gpu:\n",
    "        print(\"Transferring models to GPU(s)\")\n",
    "        model_pretrained = torch.nn.DataParallel(model_pretrained).cuda()\n",
    "        \n",
    "    pretrained_stats = train_eval(model_pretrained, trainloader, testloader, final_params)\n",
    "    pretrained_stats['name'] = name\n",
    "    pretrained_stats['retrained'] = True\n",
    "    pretrained_stats['shallow_retrain'] = True\n",
    "    stats.append(pretrained_stats)\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "print(\"---------------------\")\n",
    "print(\"TRAINING from scratch\")\n",
    "for name in models_to_test:\n",
    "    print(\"\")    \n",
    "    print(f\"Targeting {name} with {num_classes} classes\")\n",
    "    print(\"------------------------------------------\")\n",
    "    model_blank = models.__dict__[name](pretrained=False)\n",
    "\n",
    "    if name == 'inception_v3':\n",
    "        model_blank.aux_logits = False\n",
    "    \n",
    "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
    "    print(f\"Resizing input images to max of {resize}\")\n",
    "    trainloader, testloader = load_data(resize)\n",
    "    \n",
    "    if use_gpu:\n",
    "        print(\"Transferring models to GPU(s)\")\n",
    "        model_blank = torch.nn.DataParallel(model_blank).cuda()    \n",
    "        \n",
    "    blank_stats = train_eval(model_blank, trainloader, testloader)\n",
    "    blank_stats['name'] = name\n",
    "    blank_stats['retrained'] = False\n",
    "    blank_stats['shallow_retrain'] = False\n",
    "    stats.append(blank_stats)\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "t = 0.0\n",
    "for s in stats:\n",
    "    t += s.get('evaluation_time', 0) + s.get('training_time', 0)\n",
    "print(f\"Total time for training and evaluation: {t}\")\n",
    "print(\"FINISHED\")\n",
    "\n",
    "print(\"RETRAINING deep\")\n",
    "\n",
    "for name in models_to_test:\n",
    "    print(\"\")\n",
    "    print(f\"Targeting {name} with {num_classes} classes\")\n",
    "    print(\"------------------------------------------\")\n",
    "    model_pretrained, diff = load_defined_model(name, num_classes, device='cuda' if use_gpu else 'cpu')\n",
    "    \n",
    "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
    "    print(f\"Resizing input images to max of {resize}\")\n",
    "    trainloader, testloader = load_data(resize)\n",
    "    \n",
    "    if use_gpu:\n",
    "        print(\"Transferring models to GPU(s)\")\n",
    "        model_pretrained = torch.nn.DataParallel(model_pretrained).cuda()\n",
    "        \n",
    "    pretrained_stats = train_eval(model_pretrained, trainloader, testloader, None)\n",
    "    pretrained_stats['name'] = name\n",
    "    pretrained_stats['retrained'] = True\n",
    "    pretrained_stats['shallow_retrain'] = False\n",
    "    stats.append(pretrained_stats)\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "# Export stats as .csv\n",
    "with open('stats.csv', 'w') as csvfile:\n",
    "    fieldnames = stats[0].keys() if stats else []\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for s in stats:\n",
    "        writer.writerow(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final params to retrain: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Final params to retrain:\", final_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff:\", diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
