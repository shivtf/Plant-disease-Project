{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from itertools import accumulate\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "    'densenet121': 'https://download.pytorch.org/models/densenet121-241335ed.pth',\n",
    "    'densenet169': 'https://download.pytorch.org/models/densenet169-6f0f7f60.pth',\n",
    "    'densenet201': 'https://download.pytorch.org/models/densenet201-4c113574.pth',\n",
    "    'densenet161': 'https://download.pytorch.org/models/densenet161-17b70270.pth',\n",
    "    'inception_v3': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
    "    'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = model_urls.keys()\n",
    "\n",
    "input_sizes = {\n",
    "    'alexnet' : (224,224),\n",
    "    'resnet' : (224,224),\n",
    "    'inception' : (299,299),\n",
    "    'vgg' : (224,224)\n",
    "}\n",
    "\n",
    "models_to_test = ['alexnet',  'inception_v3', \\\n",
    "                  'resnet34', 'vgg13']\n",
    "# models_to_test = ['vgg13']\n",
    "\n",
    "batch_size = 30\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision.models as models\n",
    "# from torch.utils import model_zoo\n",
    "# import torchvision\n",
    "\n",
    "# def diff_states(dict_canonical, dict_subset):\n",
    "#     names1, names2 = list(dict_canonical.keys()), list(dict_subset.keys())\n",
    "\n",
    "#     not_in_1 = [n for n in names1 if n not in names2]\n",
    "#     not_in_2 = [n for n in names2 if n not in names1]\n",
    "\n",
    "#     if not_in_1:\n",
    "#         print(f\"Parameters in canonical dict but not in subset dict: {not_in_1}\")\n",
    "#     if not_in_2:\n",
    "#         print(f\"Parameters in subset dict but not in canonical dict: {not_in_2}\")\n",
    "\n",
    "#     # Only return differences for matching parameters\n",
    "#     for name in set(names1).intersection(names2):\n",
    "#         v1, v2 = dict_canonical[name], dict_subset[name]\n",
    "#         if v1.size() != v2.size():\n",
    "#             yield (name, v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "def load_defined_model(name, num_classes, device='cuda'):\n",
    "    model = models.__dict__[name](pretrained=False, num_classes=num_classes)\n",
    "    \n",
    "\n",
    "    if name == 'densenet121':\n",
    "        model.classifier = torch.nn.Linear(model.classifier.in_features, num_classes)\n",
    "    elif name == 'inception_v3':\n",
    "        model.aux_logits = False\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "        if 'AuxLogits' in model.__dict__:\n",
    "            model.AuxLogits.fc = torch.nn.Linear(model.AuxLogits.fc.in_features, num_classes)\n",
    "    elif name == 'alexnet':\n",
    "        model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    elif name == 'vgg13':\n",
    "        model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    elif name == 'resnet34':\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    model_urls = {\n",
    "        'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "        'densenet121': 'https://download.pytorch.org/models/densenet121-241335ed.pth',\n",
    "        'inception_v3': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',\n",
    "        'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "        'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    }\n",
    "    if name in model_urls:\n",
    "        pretrained_state = model_zoo.load_url(model_urls[name])\n",
    "    else:\n",
    "        raise ValueError(f\"No URL found for model '{name}'\")\n",
    "    \n",
    "    if name in ['inception_v3', 'alexnet', 'vgg13', 'resnet34']:\n",
    "        # if name == 'densenet121':\n",
    "        #     pretrained_state.pop('classifier.weight', None)\n",
    "        #     pretrained_state.pop('classifier.bias', None)\n",
    "        if name == 'inception_v3':\n",
    "            pretrained_state.pop('fc.weight', None)\n",
    "            pretrained_state.pop('fc.bias', None)\n",
    "            if 'AuxLogits.fc.weight' in pretrained_state:\n",
    "                pretrained_state.pop('AuxLogits.fc.weight', None)\n",
    "            if 'AuxLogits.fc.bias' in pretrained_state:\n",
    "                pretrained_state.pop('AuxLogits.fc.bias', None)\n",
    "        elif name == 'alexnet':\n",
    "            pretrained_state.pop('classifier.6.weight', None)\n",
    "            pretrained_state.pop('classifier.6.bias', None)\n",
    "        elif name == 'vgg13':\n",
    "            pretrained_state.pop('classifier.6.weight', None)\n",
    "            pretrained_state.pop('classifier.6.bias', None)\n",
    "        elif name == 'resnet34':\n",
    "            pretrained_state.pop('fc.weight', None)\n",
    "            pretrained_state.pop('fc.bias', None)\n",
    "\n",
    "    diff = [s for s in diff_states(model.state_dict(), pretrained_state)]\n",
    "    if diff:\n",
    "        print(f\"Replacing the following state from initialized {name}: {[d[0] for d in diff]}\")\n",
    "\n",
    "    model.load_state_dict(pretrained_state, strict=False)\n",
    "    \n",
    "    model.to(device)\n",
    "    return model, diff\n",
    "\n",
    "def diff_states(dict_canonical, dict_subset):\n",
    "    names1, names2 = list(dict_canonical.keys()), list(dict_subset.keys())\n",
    "\n",
    "    not_in_1 = [n for n in names1 if n not in names2]\n",
    "    not_in_2 = [n for n in names2 if n not in names1]\n",
    "\n",
    "    if not_in_1:\n",
    "        print(f\"Parameters in canonical dict but not in subset dict: {not_in_1}\")\n",
    "    if not_in_2:\n",
    "        print(f\"Parameters in subset dict but not in canonical dict: {not_in_2}\")\n",
    "\n",
    "    for name in set(names1).intersection(names2):\n",
    "        v1, v2 = dict_canonical[name], dict_subset[name]\n",
    "        if v1.size() != v2.size():\n",
    "            yield (name, v1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_params(net, param_list=None):\n",
    "    def in_param_list(s):\n",
    "        for p in param_list:\n",
    "            if s.endswith(p):\n",
    "                return True\n",
    "        return False    \n",
    "    params = net.named_parameters() if param_list is None \\\n",
    "    else (p for p in net.named_parameters() if in_param_list(p[0]))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def load_data(resize, val_split=0.2):\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(max(resize)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    data_dir = './plantvillage dataset/color'\n",
    "    full_dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "    val_size = int(len(full_dataset) * val_split)\n",
    "    train_size = len(full_dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    valloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    return trainloader, valloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm \n",
    "\n",
    "def train(net, trainloader, param_list=None, epochs=1, use_gpu=True):\n",
    "    net = net.train()\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "\n",
    "    if param_list:\n",
    "        params = [p for n, p in net.named_parameters() if n in param_list and p.requires_grad]\n",
    "        if not params:\n",
    "            raise ValueError(\"No valid parameters found in param_list for optimization.\")\n",
    "    else:\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "\n",
    "    if not params:\n",
    "        raise ValueError(\"Optimizer got an empty parameter list: no parameters to optimize.\")\n",
    "\n",
    "    optimizer = optim.SGD(params, lr=0.001, momentum=0.9)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  \n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(tqdm(trainloader), 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print(f\"[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        losses.append(running_loss / len(trainloader))\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stats(m, trainloader, param_list = None):\n",
    "    stats = {}\n",
    "    params = filtered_params(m, param_list)    \n",
    "    counts = 0,0\n",
    "    for counts in enumerate(accumulate((reduce(lambda d1,d2: d1*d2, p[1].size()) for p in params)) ):\n",
    "        pass\n",
    "    stats['variables_optimized'] = counts[0] + 1\n",
    "    stats['params_optimized'] = counts[1]\n",
    "    \n",
    "    before = time.time()\n",
    "    losses = train(m, trainloader, param_list=param_list)\n",
    "    stats['training_time'] = time.time() - before\n",
    "\n",
    "    stats['training_loss'] = losses[-1] if len(losses) else float('nan')\n",
    "    stats['training_losses'] = losses\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stats(net, testloader):\n",
    "    stats = {}\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    before = time.time()\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "            images, labels = (images.cuda()), (labels.cuda())\n",
    "\n",
    "        outputs = net(Variable(images))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    accuracy = correct / total\n",
    "    stats['accuracy'] = accuracy\n",
    "    stats['eval_time'] = time.time() - before\n",
    "    \n",
    "    print('Accuracy on test images: %f' % accuracy)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETRAINING\n",
      "\n",
      "Targeting alexnet with 39 classes\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters in canonical dict but not in subset dict: ['classifier.6.weight', 'classifier.6.bias']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTargeting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m classes\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (name, num_classes))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m model_pretrained, diff \u001b[38;5;241m=\u001b[39m \u001b[43mload_defined_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m final_params \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m diff]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#final_params = None\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 69\u001b[0m, in \u001b[0;36mload_defined_model\u001b[1;34m(name, num_classes, device)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Load state dict with strict=False to allow partial loading\u001b[39;00m\n\u001b[0;32m     67\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(pretrained_state, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 69\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, diff\n",
      "File \u001b[1;32mc:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Akshat Nautiyal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\cuda\\__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m     )\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "def train_eval(net, trainloader, testloader, param_list=None):\n",
    "    print(\"Training...\" if not param_list else \"Retraining...\")\n",
    "    stats_train = train_stats(net, trainloader, param_list=param_list)\n",
    "    \n",
    "    print(\"Evaluating...\")\n",
    "    net = net.eval()\n",
    "    stats_eval = evaluate_stats(net, testloader)\n",
    "    \n",
    "    return {**stats_train, **stats_eval}\n",
    "\n",
    "stats = []\n",
    "num_classes = 39\n",
    "print(\"RETRAINING\")\n",
    "\n",
    "for name in models_to_test:\n",
    "    print(\"\")\n",
    "    print(\"Targeting %s with %d classes\" % (name, num_classes))\n",
    "    print(\"------------------------------------------\")\n",
    "    model_pretrained, diff = load_defined_model(name, num_classes)\n",
    "    final_params = [d[0] for d in diff]\n",
    "    #final_params = None\n",
    "    \n",
    "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
    "    print(\"Resizing input images to max of\", resize)\n",
    "    trainloader, testloader = load_data(resize)\n",
    "    \n",
    "    if use_gpu:\n",
    "        print(\"Transfering models to GPU(s)\")\n",
    "        model_pretrained = torch.nn.DataParallel(model_pretrained).cuda()\n",
    "        \n",
    "    pretrained_stats = train_eval(model_pretrained, trainloader, testloader, final_params)\n",
    "    pretrained_stats['name'] = name\n",
    "    pretrained_stats['retrained'] = True\n",
    "    pretrained_stats['shallow_retrain'] = True\n",
    "    stats.append(pretrained_stats)\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "print(\"---------------------\")\n",
    "print(\"TRAINING from scratch\")\n",
    "for name in models_to_test:\n",
    "    print(\"\")    \n",
    "    print(\"Targeting %s with %d classes\" % (name, num_classes))\n",
    "    print(\"------------------------------------------\")\n",
    "    model_blank = models.__dict__[name](num_classes=num_classes)\n",
    "\n",
    "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
    "    print(\"Resizing input images to max of\", resize)\n",
    "    trainloader, testloader = load_data(resize)\n",
    "    \n",
    "    if use_gpu:\n",
    "        print(\"Transfering models to GPU(s)\")\n",
    "        model_blank = torch.nn.DataParallel(model_blank).cuda()    \n",
    "        \n",
    "    blank_stats = train_eval(model_blank, trainloader, testloader)\n",
    "    blank_stats['name'] = name\n",
    "    blank_stats['retrained'] = False\n",
    "    blank_stats['shallow_retrain'] = False\n",
    "    stats.append(blank_stats)\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "t = 0.0\n",
    "for s in stats:\n",
    "    t += s['eval_time'] + s['training_time']\n",
    "print(\"Total time for training and evaluation\", t)\n",
    "print(\"FINISHED\")\n",
    "\n",
    "print(\"RETRAINING deep\")\n",
    "\n",
    "for name in models_to_test:\n",
    "    print(\"\")\n",
    "    print(\"Targeting %s with %d classes\" % (name, num_classes))\n",
    "    print(\"------------------------------------------\")\n",
    "    model_pretrained, diff = load_defined_model(name, num_classes)\n",
    "    \n",
    "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
    "    print(\"Resizing input images to max of\", resize)\n",
    "    trainloader, testloader = load_data(resize)\n",
    "    \n",
    "    if use_gpu:\n",
    "        print(\"Transfering models to GPU(s)\")\n",
    "        model_pretrained = torch.nn.DataParallel(model_pretrained).cuda()\n",
    "        \n",
    "    pretrained_stats = train_eval(model_pretrained, trainloader, testloader, None)\n",
    "    pretrained_stats['name'] = name\n",
    "    pretrained_stats['retrained'] = True\n",
    "    pretrained_stats['shallow_retrain'] = False\n",
    "    stats.append(pretrained_stats)\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "import csv\n",
    "with open('stats.csv', 'w') as csvfile:\n",
    "    fieldnames = stats[0].keys()\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for s in stats:\n",
    "        writer.writerow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
